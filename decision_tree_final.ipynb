{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "\n",
    "train_X = pd.read_csv(\"train_X_Final_order2.csv\",low_memory=True)\n",
    "train_Y = pd.read_csv(\"train_Y_Final_order2.csv\",low_memory=True)\n",
    "test = pd.read_csv(\"test_final_order2.csv\",index_col='ncodpers')\n",
    "test.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT LABEL ENCODER HERE  #########\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "strings = [col for col in train_X.columns if train_X[col].dtype == object]\n",
    "#test.columns=[i+'_0' for i in test.columns]\n",
    "\n",
    "fit_col = []\n",
    "for i in range(len(strings)):\n",
    "    print(strings[i],list((train_X[strings[i]].unique())),list((test[strings[i]].unique())))\n",
    "    test[strings[i]]=test[strings[i]].astype(str)\n",
    "    train_X[strings[i]]=train_X[strings[i]].astype(str)\n",
    "    fit_col.append(le.fit((train_X[strings[i]].append(test[strings[i]])).astype(str)))\n",
    "    train_X[strings[i]] = fit_col[i].transform(train_X[strings[i]])\n",
    "    test[strings[i]] = fit_col[i].transform(test[strings[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y=train_Y.astype(bool)\n",
    "train_X=train_X.astype(np.int32)\n",
    "test=test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added products\n",
    "train_X_prod=[col for col in train_X.columns if 'ult1_1' in col]\n",
    "train_Y=train_Y.astype(int)-train_X.loc[:,train_X_prod]\n",
    "train_Y[train_Y < 0] = 0\n",
    "train_Y=train_Y.astype(bool)\n",
    "train_Y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"added products\"\"\"\n",
    "train_X_prod_prev=[col for col in train_X.columns if 'ult1_0' in col]\n",
    "train_X.loc[:,train_X_prod]=train_X.loc[:,train_X_prod]-train_X.loc[:,train_X_prod_prev].values\n",
    "train_X[train_X<0] = 0\n",
    "train_X.loc[:,train_X_prod].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with all 0s\n",
    "Ynot1 = (train_Y == 0).all(axis=1)\n",
    "train_Y=train_Y[~Ynot1]\n",
    "train_X=train_X[~Ynot1]\n",
    "train_Y.drop([col for col, val in train_Y.sum().iteritems() if val < 5000], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.multioutput import MultiOutputClassifier \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_Y, \n",
    "                                                    test_size=0.06, train_size=0.24, \n",
    "                                                    random_state=40)\n",
    "\n",
    "#clf = DecisionTreeClassifier(random_state=40, criterion='gini',max_depth=10)\n",
    "\n",
    "clf = MultiOutputClassifier(GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=4,\n",
    "                                                       random_state=40),n_jobs=8)\n",
    "\n",
    "#clf.fit(train_X,train_Y)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score,average_precision_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print('acc',accuracy_score(y_pred, y_test),'prec',precision_score(y_test,y_pred,average='micro'))\n",
    "\n",
    "#(random_state=40, criterion='gini',max_depth=5) -> acc 0.7520150492974298 prec 0.8042921809776741\n",
    "#(random_state=40, criterion='gini',max_depth=8) -> \n",
    "#(random_state=40, criterion='gini',max_depth=10) -> \n",
    "#(random_state=40, criterion='gini',max_depth=12) -> \n",
    "#(random_state=40, criterion='gini',max_depth=15) -> acc 0.9238697615460784 prec 0.9674549120238518\n",
    "#(random_state=40, criterion='gini',max_depth=18) -> acc 0.9282355411543959 prec 0.9704043581751023\n",
    "#(random_state=40, criterion='gini',max_depth=20) -> acc 0.9280332656513078 prec 0.9703055805614199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = clf.feature_importances_\n",
    "# summarize feature importance\n",
    "\n",
    "ind=[]\n",
    "val=[]\n",
    "for i,v in enumerate(importance):\n",
    "    #imp.append(pd.Series([v],index=[train_X.columns[i][:-2]]))\n",
    "    ind.append(train_X.columns[i][:-2])\n",
    "    val.append(v)\n",
    "    #print(pd.Series([v],index=[train_X.columns[i][:-2]]))\n",
    "\t#print('Feature:',train_X.columns[i], 'Score: %.5f' % (v))\n",
    "imp=pd.Series(val,index=ind,name='importance',dtype=float)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.bar(imp.index, imp, color='green')\n",
    "plt.xlabel(\"Variable\")\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "plt.title(\"Importance\")\n",
    "plt.xticks(imp.index, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(test)\n",
    "y_pred_df = pd.DataFrame(columns=train_Y.columns,index=test.index)\n",
    "for i,j in zip(y_pred,train_Y.columns):\n",
    "    y_pred_df[j]=i[:,1]\n",
    "    \n",
    "y_pred_df.columns=[i[:-2] for i in y_pred_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prev = pd.read_csv(\"train_2016052018.csv\",index_col='ncodpers')\n",
    "train_prev.columns = [col[:-1] if '_201' not in col else col[:-11] for col in train_prev.columns]\n",
    "y_pred_df=y_pred_df.sort_index()\n",
    "train_prev=train_prev.sort_index()\n",
    "train_prev = train_prev[train_prev.index.isin(y_pred_df.index)]\n",
    "print(train_prev.shape,y_pred_df.shape)\n",
    "output = y_pred_df-train_prev\n",
    "output[output < 0] = 0\n",
    "output.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.apply(lambda x: (x.nlargest(n=7,keep=\"first\").index), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = output.apply(lambda x: ' '.join(x[x!='']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile.name = 'added_products'\n",
    "outfile.index.rename('ncodpers',inplace=True)\n",
    "outfile.to_csv('outfile_gb4_order2.csv',sep=',',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
